# ZERNIKEPro
2024.05

## Code Structure:
  * waveFrontCorr: Main network
  * Non-local Attention Block:
     1- nonLocal Block: Original coding of NLP
     2- selfAttention Block: First common version of the nonLocal Block applied in CV, which has too many parameters
     3- transformer: Multi-head attention
  * dataLoader:
      Preprocess data using zerNikeDataLoader.py and dataPreprocess.py

## Zernike Project Research Links:
  * Graduate Weekly Report: https://onedrive.live.com/redir?resid=ADB8A54F495E79DC%2115588&authkey=%21AjAZ6pw-YmVlu0o&page=Edit&wd=target%28%E5%B4%94%E6%99%93%E9%9B%85.one%7C934f3553-776f-405b-99ab-0d7e9b842c64%2F%E6%B3%BD%E5%B0%BC%E5%85%8B%E9%A1%B9%E7%9B%AE%E8%B0%83%E7%A0%94%7Cff349379-0c8b-41b8-ae78-184b87aa998e%2F%29&wdorigin=NavigationUrl
  * notion : https://www.notion.so/Lab610-01f01d2992f94cf9a98fce6f00d8ff51?pvs=4
